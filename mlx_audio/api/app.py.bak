"""MLX-Audio FastAPI ä¸‰åˆä¸€åº”ç”¨ - UI/API/MCPé›†æˆ"""
import asyncio
import io
import os
import time
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Optional

import mlx.core as mx
import soundfile as sf
import uvicorn
from fastapi import FastAPI, File, Form, HTTPException, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

from mlx_audio.config import config
from mlx_audio.models.memory_manager import memory_manager
from mlx_audio.utils import load_model


# === Pydantic Models ===
class SpeechRequest(BaseModel):
    model: str = config.model.default_tts_model
    input: str
    voice: Optional[str] = None
    speed: float = 1.0
    lang_code: str = "a"
    temperature: float = 0.7
    response_format: str = "wav"


class ModelRequest(BaseModel):
    model_name: str


# === Lifespan ===
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸ”„ é¢„åŠ è½½æ¨¡å‹...")
    for model_name in config.model.preload_models:
        try:
            get_tts_model(model_name) if "whisper" not in model_name.lower() else get_stt_model(model_name)
            print(f"  âœ… {model_name}")
        except Exception as e:
            print(f"  âš ï¸  {model_name}: {e}")
    
    asyncio.create_task(memory_manager.start_cleanup_loop())
    yield
    memory_manager.stop_cleanup_loop()
    memory_manager.release_all()


# === App ===
app = FastAPI(
    title="MLX-Audio",
    description="TTS/STT API on Apple Silicon",
    version="0.2.0",
    docs_url="/docs",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# === Helper ===
def get_tts_model(model_name: str):
    return memory_manager.get_model(model_name, lambda: load_model(model_name))


def get_stt_model(model_name: str):
    return memory_manager.get_model(model_name, lambda: load_model(model_name))


# è¯­è¨€å¯¹åº”çš„é»˜è®¤å£°éŸ³
LANG_DEFAULT_VOICE = {
    "a": "af_heart",
    "b": "bf_emma", 
    "z": "zf_xiaobei",
    "j": "jf_alpha",
}


# === API Routes ===
@app.get("/api/health")
async def health():
    return {"status": "ok", "models": memory_manager.get_stats()}


@app.get("/v1/models")
async def list_models():
    models = memory_manager.list_models()
    return {
        "object": "list",
        "data": [{"id": m, "object": "model", "created": int(time.time())} for m in models]
    }


@app.post("/v1/models")
async def add_model(req: ModelRequest):
    get_tts_model(req.model_name)
    return {"status": "success", "message": f"Model {req.model_name} loaded"}


@app.delete("/v1/models/{model_name}")
async def remove_model(model_name: str):
    if memory_manager.release(model_name):
        return {"status": "success"}
    raise HTTPException(404, f"Model '{model_name}' not found")


@app.post("/v1/audio/speech")
async def tts_speech(payload: SpeechRequest):
    """ç”Ÿæˆè¯­éŸ³ - æ”¯æŒä¸­è‹±æ—¥å¤šè¯­è¨€"""
    model = get_tts_model(payload.model)
    voice = payload.voice or LANG_DEFAULT_VOICE.get(payload.lang_code, "af_heart")
    
    async def generate():
        for result in model.generate(
            payload.input,
            voice=voice,
            speed=payload.speed,
            lang_code=payload.lang_code,
            temperature=payload.temperature,
        ):
            buf = io.BytesIO()
            sf.write(buf, result.audio, result.sample_rate, format=payload.response_format)
            buf.seek(0)
            yield buf.getvalue()
    
    return StreamingResponse(
        generate(),
        media_type=f"audio/{payload.response_format}",
        headers={"Content-Disposition": f"attachment; filename=speech.{payload.response_format}"}
    )


@app.post("/v1/audio/speech/stream")
async def tts_speech_stream(payload: SpeechRequest):
    """æµå¼ç”Ÿæˆè¯­éŸ³ - PCMæ ¼å¼å®æ—¶è¾“å‡º"""
    model = get_tts_model(payload.model)
    voice = payload.voice or LANG_DEFAULT_VOICE.get(payload.lang_code, "af_heart")
    
    async def generate_pcm():
        import numpy as np
        for result in model.generate(
            payload.input,
            voice=voice,
            speed=payload.speed,
            lang_code=payload.lang_code,
            temperature=payload.temperature,
            stream=True,
            streaming_interval=0.5,
        ):
            # è½¬æ¢ä¸ºPCM Int16
            audio_int16 = (np.array(result.audio) * 32767).astype(np.int16)
            yield audio_int16.tobytes()
    
    return StreamingResponse(
        generate_pcm(),
        media_type="audio/pcm",
        headers={
            "X-Sample-Rate": "24000",
            "X-Channels": "1",
            "X-Bit-Depth": "16"
        }
    )


@app.post("/v1/audio/transcriptions")
async def stt_transcriptions(
    file: UploadFile = File(...),
    model: str = Form(config.model.default_stt_model),
    language: Optional[str] = Form(None),
    prompt: Optional[str] = Form(None),
):
    """è¯­éŸ³è½¬æ–‡å­— - æ”¯æŒæç¤ºè¯æé«˜å‡†ç¡®ç‡
    
    å‚æ•°:
    - file: éŸ³é¢‘æ–‡ä»¶
    - model: STTæ¨¡å‹
    - language: è¯­è¨€ï¼ˆå¯é€‰ï¼‰
    - prompt: æç¤ºè¯ï¼ˆå¯é€‰ï¼Œç”¨äºæé«˜è¯†åˆ«å‡†ç¡®ç‡ï¼Œå¦‚ä¸“ä¸šæœ¯è¯­ã€äººåç­‰ï¼‰
    """
    data = await file.read()
    tmp = io.BytesIO(data)
    audio, sr = sf.read(tmp, always_2d=False)
    tmp_path = f"/tmp/{time.time()}.wav"
    sf.write(tmp_path, audio, sr)
    
    stt_model = get_stt_model(model)
    result = stt_model.generate(
        tmp_path, 
        language=language if language != "Detect" else None,
        initial_prompt=prompt
    )
    os.remove(tmp_path)
    
    return {"text": result.text}


# === Voice Clone API ===
@app.post("/v1/audio/clone")
async def voice_clone(
    file: UploadFile = File(...),
    text: str = Form(...),
    model: str = Form("mlx-community/csm-1b"),
    ref_text: str = Form("This is a reference audio sample."),
):
    """å£°éŸ³å…‹éš† - ä½¿ç”¨å‚è€ƒéŸ³é¢‘ç”Ÿæˆè¯­éŸ³
    
    å‚æ•°:
    - file: å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼ˆç”¨äºå…‹éš†å£°éŸ³ï¼‰
    - text: è¦åˆæˆçš„æ–‡æœ¬
    - ref_text: å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹ï¼ˆæè¿°å‚è€ƒéŸ³é¢‘è¯´äº†ä»€ä¹ˆï¼‰
    """
    # ä¿å­˜ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘
    data = await file.read()
    tmp_ref = f"/tmp/ref_{time.time()}.wav"
    
    with open(tmp_ref, "wb") as f:
        f.write(data)
    
    try:
        # åŠ è½½æ¨¡å‹
        clone_model = get_tts_model(model)
        
        # åŠ è½½å‚è€ƒéŸ³é¢‘
        from mlx_audio.tts.generate import load_audio
        ref_audio = load_audio(tmp_ref, sample_rate=clone_model.sample_rate)
        
        # ç”Ÿæˆå…‹éš†è¯­éŸ³
        results = list(clone_model.generate(
            text,
            ref_audio=ref_audio,
            ref_text=ref_text,
        ))
        
        if not results:
            raise HTTPException(500, "No audio generated")
        
        # è¿”å›éŸ³é¢‘
        buf = io.BytesIO()
        sf.write(buf, results[0].audio, results[0].sample_rate, format="wav")
        buf.seek(0)
        
        return StreamingResponse(
            iter([buf.getvalue()]),
            media_type="audio/wav",
            headers={"Content-Disposition": "attachment; filename=cloned.wav"}
        )
    finally:
        if os.path.exists(tmp_ref):
            os.remove(tmp_ref)


# === MCP Routes ===
@app.get("/mcp/tools")
async def mcp_list_tools():
    return {
        "tools": [
            {"name": "tts", "description": "Text to Speech - æ”¯æŒä¸­è‹±æ—¥"},
            {"name": "stt", "description": "Speech to Text"},
            {"name": "list_models", "description": "List loaded models"},
        ]
    }


@app.post("/mcp/call/{tool_name}")
async def mcp_call_tool(tool_name: str, params: dict):
    if tool_name == "tts":
        model = get_tts_model(params.get("model", config.model.default_tts_model))
        lang_code = params.get("lang_code", "a")
        voice = params.get("voice") or LANG_DEFAULT_VOICE.get(lang_code, "af_heart")
        results = list(model.generate(
            params["text"],
            voice=voice,
            speed=params.get("speed", 1.0),
            lang_code=lang_code,
        ))
        if results:
            path = config.model.output_dir / f"tts_{int(time.time())}.wav"
            sf.write(str(path), results[0].audio, results[0].sample_rate)
            return {"status": "success", "file": str(path)}
        return {"status": "error", "message": "No audio generated"}
    
    elif tool_name == "stt":
        model = get_stt_model(params.get("model", config.model.default_stt_model))
        result = model.generate(params["audio_path"])
        return {"text": result.text}
    
    elif tool_name == "list_models":
        return memory_manager.get_stats()
    
    raise HTTPException(404, f"Tool '{tool_name}' not found")


# === Static Files (UI) ===
static_dir = Path(__file__).parent / "static"
if static_dir.exists():
    app.mount("/", StaticFiles(directory=str(static_dir), html=True), name="static")


def main():
    import argparse
    parser = argparse.ArgumentParser(description="MLX-Audio Server")
    parser.add_argument("--host", default=config.server.host)
    parser.add_argument("--port", type=int, default=config.server.port)
    parser.add_argument("--reload", action="store_true")
    args = parser.parse_args()
    
    print(f"ğŸš€ MLX-Audio Server: http://{args.host}:{args.port}")
    print(f"ğŸ“š API Docs: http://{args.host}:{args.port}/docs")
    
    uvicorn.run(
        "mlx_audio.api.app:app",
        host=args.host,
        port=args.port,
        reload=args.reload,
    )


if __name__ == "__main__":
    main()
